{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = '../data/raw'\n",
    "interim_dir = '../data/interim/'\n",
    "external_dir = '../data/external'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_files = pd.DataFrame({'file_path' : sorted(glob.glob(f'{raw_dir}/*.xlsx'))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_files['variable_type'] = \\\n",
    "    source_files['file_path'] \\\n",
    "        .replace('../data/raw/[0-9][a-z] - ', '', regex=True) \\\n",
    "            .replace('.xlsx', '', regex=True).replace('\\W{1,}', '_', regex=True) \\\n",
    "                .str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for i in source_files.index:\n",
    "    dfs[source_files.loc[i,'variable_type']] =  pd.read_excel(source_files.loc[i,'file_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv(f'{external_dir}/WPP2022_Demographic_Indicators_Medium.csv', usecols=['Location', 'Time', 'TPopulation1Jan', 'TPopulation1July'])\n",
    "population = population.rename(columns = {'Location' : 'country', 'Time' : 'year', 'TPopulation1Jan' : 'population_boy', 'TPopulation1July' : 'population_mid'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_producer(df, var_name, time_name):\n",
    "    \"\"\" Processes producer data\n",
    "        df: pandas DataFrame containing raw producer data\n",
    "        var_name:   variable name to process (production, consumption, openstock, or exports)\n",
    "        time:name:  crop_year or calendar_year\n",
    "    \"\"\"\n",
    "    x = df\n",
    "    x.columns = x.iloc[2, :]\n",
    "    x = x.iloc[3:(x.shape[0]-1), :]\n",
    "    x = x.dropna(how='all')\n",
    "    x = x.loc[:,x.columns.notna()]\n",
    "    x.rename(columns={'Crop year' : 'country', 'Crop years' : 'country', 'Calendar years' : 'country'}, inplace=True)\n",
    "    x = x.melt(id_vars='country', var_name = time_name, value_name=f'{var_name}_1k_bags')\n",
    "    x['country'] = x['country'].str.strip()\n",
    "    x[f'{var_name}_1k_bags'] = x[f'{var_name}_1k_bags'].astype('float', errors='ignore')\n",
    "    x[f'{var_name}_kg'] = x[f'{var_name}_1k_bags'] * 1000 * 60\n",
    "    x[f'{var_name}_lb'] = x[f'{var_name}_kg'] * 2.20462262185\n",
    "    harvest_groups = ['April group', 'July group', 'October group']\n",
    "    totals = ['Total']\n",
    "    x['harvest_group'] = np.where(x['country'].isin(harvest_groups), x['country'].str.replace(r' [Gg]roup', '', regex=True), np.NaN)\n",
    "    x['harvest_group'] = x['harvest_group'].ffill()\n",
    "    if time_name == 'crop_year':\n",
    "        x['crop_year_beg'] = x['crop_year'].str[0:4].astype('int')\n",
    "        x['crop_year_end'] = x['crop_year_beg']+1\n",
    "    hg_rows = x.iloc[:,0].isin(harvest_groups)\n",
    "    tot_rows = x.iloc[:,0].isin(totals)\n",
    "    x = x.loc[~(hg_rows|tot_rows)]\n",
    "    if time_name == 'crop_year':\n",
    "        x = x[['country', 'harvest_group','crop_year', 'crop_year_beg', 'crop_year_end',f'{var_name}_1k_bags',f'{var_name}_kg',f'{var_name}_lb']]\n",
    "    else:\n",
    "        x = x[['country', 'calendar_year',f'{var_name}_1k_bags',f'{var_name}_kg',f'{var_name}_lb']]\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['total_production'] = process_producer(dfs['total_production'], 'production', 'crop_year')\n",
    "dfs['domestic_consumption'] = process_producer(dfs['domestic_consumption'], 'consumption', 'crop_year')\n",
    "dfs['gross_opening_stocks'] = process_producer(dfs['gross_opening_stocks'], 'openstock', 'crop_year')\n",
    "dfs['exports_crop_year'] = process_producer(dfs['exports_crop_year'], 'exports', 'crop_year')\n",
    "dfs['exports_calendar_year'] = process_producer(dfs['exports_calendar_year'], 'exports', 'calendar_year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_map = pd.DataFrame(\n",
    "    {'country' : ['Austria','Belgium','Belgium/Luxembourg','Bulgaria','Croatia','Cyprus','Czechia','Denmark','Estonia','Finland','France','Germany',\n",
    "'Greece','Hungary','Ireland','Italy','Latvia','Lithuania','Luxembourg','Malta','Netherlands','Poland','Portugal',\n",
    "'Romania','Slovakia','Slovenia','Spain','Sweden','Japan','Norway','Russian Federation','Switzerland','Tunisia','United Kingdom','United States of America']\n",
    ",\n",
    "'region' : ['Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe',\n",
    "'Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe','Europe',\n",
    "'Europe','Asia & Oceania','Europe','Europe','Europe','Africa','Europe','North America']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_importer(df, var_name, region_map):\n",
    "    x = df\n",
    "    x.columns = x.iloc[2, :]\n",
    "    x = x.iloc[3:43, :]\n",
    "    x = x.dropna(how='all')\n",
    "    x.rename(columns={'Calendar years' : 'country'}, inplace=True)\n",
    "    x = x.melt(id_vars='country', var_name = 'calendar_year', value_name=f'{var_name}_1k_bags')\n",
    "    x['country'] = x['country'].str.strip()\n",
    "    x[f'{var_name}_1k_bags'] = x[f'{var_name}_1k_bags'].astype('float', errors='ignore')\n",
    "    eu = ['European Union']\n",
    "    eu_rows = x.iloc[:,0].isin(eu)\n",
    "    totals = ['Total']\n",
    "    tot_rows = x.iloc[:,0].isin(totals)\n",
    "    x = x.loc[~(eu_rows|tot_rows)]\n",
    "    x = x.merge(region_map, how = 'left', on = 'country')\n",
    "    x['ico_member'] = 'member'\n",
    "\n",
    "    B = x.loc[lambda x: x.country.isin(['Belgium']) & (x.calendar_year >= 1999), ['calendar_year', f'{var_name}_1k_bags']]\n",
    "    L = x.loc[lambda x: x.country.isin(['Luxembourg']) & (x.calendar_year >= 1999), ['calendar_year', f'{var_name}_1k_bags']]\n",
    "\n",
    "    BL = \\\n",
    "        B \\\n",
    "            .merge(L, how = 'left', on = 'calendar_year', suffixes=['_B', '_L']) \\\n",
    "                .assign(tot = lambda x: x[f'{var_name}_1k_bags_B'] + x[f'{var_name}_1k_bags_L'],\n",
    "                        B_ratio = lambda x: x[f'{var_name}_1k_bags_B']/x.tot)\n",
    "\n",
    "    belg_ratio = BL[f'{var_name}_1k_bags_B'].sum() / BL.tot.sum()\n",
    "\n",
    "    calced_split = \\\n",
    "    x \\\n",
    "    .loc[lambda x: x.country.isin(['Belgium/Luxembourg']), ['calendar_year', f'{var_name}_1k_bags']] \\\n",
    "    .assign(**{f'{var_name}_1k_bags_B' : lambda x: x[f'{var_name}_1k_bags'] * belg_ratio,\n",
    "                f'{var_name}_1k_bags_L' : lambda x: x[f'{var_name}_1k_bags'] * (1-belg_ratio)})\n",
    "\n",
    "    B = calced_split[['calendar_year', f'{var_name}_1k_bags_B']] \\\n",
    "        .assign(country = 'Belgium') \\\n",
    "            .rename(columns={f'{var_name}_1k_bags_B' : f'{var_name}_1k_bags'})\n",
    "    \n",
    "    L = calced_split[['calendar_year', f'{var_name}_1k_bags_L']] \\\n",
    "        .assign(country = 'Luxembourg') \\\n",
    "            .rename(columns={f'{var_name}_1k_bags_L' : f'{var_name}_1k_bags'})\n",
    "    \n",
    "    BL = pd.concat([B, L]).reset_index(drop=True)[['calendar_year', 'country', f'{var_name}_1k_bags']]\n",
    "\n",
    "    x = \\\n",
    "    x \\\n",
    "    .merge(BL, how = 'left', on = ['calendar_year', 'country'], suffixes = ['', '_calc']) \\\n",
    "    .assign(**{f'{var_name}_1k_bags' : lambda x: np.where(x[f'{var_name}_1k_bags'].isna(), x[f'{var_name}_1k_bags_calc'], x[f'{var_name}_1k_bags'])}) \\\n",
    "    .loc[lambda x: ~x.country.isin(['Belgium/Luxembourg']), \n",
    "        ['region', 'country', 'ico_member', 'calendar_year', f'{var_name}_1k_bags']]\n",
    "\n",
    "    x[f'{var_name}_kg'] = x[f'{var_name}_1k_bags'] * 1000 * 60\n",
    "    x[f'{var_name}_lb'] = x[f'{var_name}_kg'] * 2.20462262185\n",
    "\n",
    "    x = x[['region', 'country','ico_member', 'calendar_year', f'{var_name}_1k_bags', f'{var_name}_kg', f'{var_name}_lb']]\n",
    "    \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['imports'] = process_importer(dfs['imports'], 'imports')\n",
    "dfs['re_exports'] = process_importer(dfs['re_exports'], 're_exports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "member = \\\n",
    "dfs['imports'] \\\n",
    "    .merge(dfs['re_exports'], how = 'outer', on = ['region', 'country', 'ico_member', 'calendar_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nonmember(df, var_name):\n",
    "    x = df\n",
    "    x.columns = x.iloc[2, :]\n",
    "    x = x.iloc[3:(df.shape[0]-1), :]\n",
    "    x = x.dropna(how='all')\n",
    "    x.rename(columns={'Calendar years' : 'country'}, inplace=True)\n",
    "    x = x.melt(id_vars='country', var_name = 'calendar_year', value_name=f'{var_name}_1k_bags')\n",
    "    x['country'] = x['country'].str.strip()\n",
    "    x[f'{var_name}_1k_bags'] = x[f'{var_name}_1k_bags'].astype('float', errors='ignore')\n",
    "    x[f'{var_name}_kg'] = x[f'{var_name}_1k_bags'] * 1000 * 60\n",
    "    x[f'{var_name}_lb'] = x[f'{var_name}_kg'] * 2.20462262185\n",
    "    china_agg = x.iloc[:,0].isin([\"China, People's Republic of\"])\n",
    "    x = x[~china_agg]\n",
    "    regions = ['Africa','Asia & Oceania','Caribbean','Central America & Mexico','Europe','North America','South America']\n",
    "    totals = ['Total']\n",
    "    x['region'] = np.where(x['country'].isin(regions), x['country'], np.NaN)\n",
    "    x['region'] = x['region'].ffill()\n",
    "    x['ico_member'] = 'non-member'\n",
    "    region_rows = x.iloc[:,0].isin(regions)\n",
    "    tot_rows = x.iloc[:,0].isin(totals)\n",
    "    x = x.loc[~(region_rows|tot_rows)]\n",
    "    x = x[['region','country','ico_member','calendar_year',f'{var_name}_1k_bags',f'{var_name}_kg',f'{var_name}_lb']]\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['non_member_imports'] = process_nonmember(dfs['non_member_imports'], 'imports')\n",
    "dfs['non_member_re_exports'] = process_nonmember(dfs['non_member_re_exports'], 're_exports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_member = \\\n",
    "dfs['non_member_imports'] \\\n",
    "    .merge(dfs['non_member_re_exports'], how = 'outer', on = ['region', 'country', 'ico_member', 'calendar_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports_re_exports = pd.concat([member, non_member]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmr_yugoslavia = \\\n",
    "    population \\\n",
    "        .loc[lambda x: x.country.isin(['Serbia', 'Croatia', 'Slovenia', 'Bosnia and Herzegovina', 'Macedonia'])] \\\n",
    "        .groupby('year') \\\n",
    "        .agg({'population_boy' : sum, 'population_mid' : sum}) \\\n",
    "        .reset_index() \\\n",
    "        .assign(country = 'Yugoslavia SFR') \\\n",
    "        .loc[:, ['country', 'year', 'population_boy', 'population_mid']]\n",
    "\n",
    "net_antilles = \\\n",
    "    population \\\n",
    "        .loc[lambda x: x.country.isin(['Curacao', 'Bonaire', 'Aruba', 'Sint Maarten (Dutch part)', 'Sint Eustatius', 'Saba', 'Netherlands Antilles'])] \\\n",
    "        .groupby('year') \\\n",
    "        .agg({'population_boy' : sum, 'population_mid' : sum}) \\\n",
    "        .reset_index() \\\n",
    "        .assign(country = 'Netherlands Antilles (former)') \\\n",
    "        .loc[:, ['country', 'year', 'population_boy', 'population_mid']]\n",
    "\n",
    "population = pd.concat([population, fmr_yugoslavia, net_antilles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrymap = \\\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'country' : \n",
    "            ['Abu Dhabi',\n",
    "            'China (Mainland)',\n",
    "            \"Democratic People's Republic of Korea\",\n",
    "            'Dubai',\n",
    "            'Hong Kong',\n",
    "            'Macao',\n",
    "            'Micronesia (Federated States of)',\n",
    "            'Netherlands Antilles (former)',\n",
    "            'Saint Vincent & the Grenadines',\n",
    "            'Taiwan',\n",
    "            'Turkey',\n",
    "            'USSR'],\n",
    "\n",
    "        'country_pop' :\n",
    "            ['United Arab Emirates',\n",
    "            'China',\n",
    "            \"Dem. People's Republic of Korea\",\n",
    "            'United Arab Emirates',\n",
    "            'China, Hong Kong SAR',\n",
    "            'China, Macao SAR',\n",
    "            'Micronesia',\n",
    "            'Netherlands Antilles (former)',\n",
    "            'Saint Vincent and the Grenadines',\n",
    "            'China, Taiwan Province of China',\n",
    "            'Türkiye',\n",
    "            'Russian Federation']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports_re_exports = \\\n",
    "imports_re_exports \\\n",
    "    .merge(countrymap, how = 'left', on='country') \\\n",
    "    .assign(country_pop = lambda x: np.where(x.country_pop.isna(), x.country, x.country_pop)) \n",
    "\n",
    "imports_re_exports = \\\n",
    "    imports_re_exports \\\n",
    "        .merge(population, how = 'left', left_on=['country_pop', 'calendar_year'], right_on = ['country', 'year'], suffixes = ['', '_y']) \\\n",
    "            .drop(columns=['year', 'country_y'])\n",
    "            \n",
    "imports_re_exports.drop(columns='country_pop', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfs['prices_paid_to_growers']\n",
    "x.columns = x.iloc[2, :]\n",
    "x = x.iloc[3:76, :]\n",
    "x = x.dropna(how='all')\n",
    "x.rename(columns={'Calendar years' : 'country'}, inplace=True)\n",
    "x = x.melt(id_vars='country', var_name = 'calendar_year', value_name='price_paid_cents_per_lb')\n",
    "x['country'] = x['country'].str.strip()\n",
    "x['price_paid_cents_per_lb'] = x['price_paid_cents_per_lb'].astype('float', errors='ignore')\n",
    "x['price_paid_dollars_per_lb'] = x['price_paid_cents_per_lb'] / 100\n",
    "categories = ['Colombian Milds', 'Other Milds', 'Brazilian Naturals', 'Robustas']\n",
    "totals = ['Total', '']\n",
    "x['indicator_name'] = np.where(x['country'].isin(categories), x['country'], np.NaN)\n",
    "x['indicator_name'] = x['indicator_name'].ffill()\n",
    "cat_rows = x.iloc[:,0].isin(categories)\n",
    "tot_rows = x.iloc[:,0].isin(totals)\n",
    "x = x.loc[~(cat_rows|tot_rows)]\n",
    "x['indicator_name'] = x['indicator_name'].str.replace(' ', '_').str.lower()\n",
    "x = x[['country', 'indicator_name', 'calendar_year', 'price_paid_cents_per_lb', 'price_paid_dollars_per_lb']]\n",
    "dfs['prices_paid_to_growers'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfs['indicator_prices']\n",
    "x.columns = x.iloc[2, :]\n",
    "x = x.iloc[3:424, :]\n",
    "x = x.dropna(how='all')\n",
    "x.columns = x.columns.fillna('calendar_month').str.replace('\\\\n', '', regex=True).str.replace(' ', '_', regex=True).str.lower()\n",
    "x = x.melt(id_vars='calendar_month', var_name='indicator_name', value_name='indicator_price_cents_per_lb')\n",
    "x['indicator_price_cents_per_lb'] = x['indicator_price_cents_per_lb'].astype('float', errors = 'ignore')\n",
    "x['indicator_price_dollars_per_lb'] = x['indicator_price_cents_per_lb'] / 100\n",
    "year_rows = x['calendar_month'].astype('str').str.match(r'[0-9]{4}')\n",
    "x['calendar_year'] = np.where(year_rows, x['calendar_month'], np.NaN)\n",
    "x['calendar_year'] = x['calendar_year'].fillna(method='ffill')\n",
    "avg_annual = x[year_rows].drop(columns='calendar_month')\n",
    "x = x[~year_rows]\n",
    "x = x.merge(avg_annual, how = 'left', on = ['calendar_year', 'indicator_name'], suffixes=['', '_ann'])\n",
    "x = x[['calendar_year','calendar_month','indicator_name','indicator_price_cents_per_lb','indicator_price_dollars_per_lb', 'indicator_price_cents_per_lb_ann','indicator_price_dollars_per_lb_ann']]\n",
    "dfs['indicator_prices'] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Interim Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in dfs.keys():\n",
    "    dfs[k].to_csv(f'{interim_dir}/{k}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge Producing Country Crop Year Data\n",
    "producer_cropyear = \\\n",
    "    dfs['gross_opening_stocks'] \\\n",
    "        .merge(dfs['total_production'], \n",
    "        how = 'left', \n",
    "        on = ['country', 'harvest_group','crop_year', 'crop_year_beg', 'crop_year_end'])\n",
    "\n",
    "producer_cropyear = \\\n",
    "    producer_cropyear \\\n",
    "        .merge(dfs['domestic_consumption'], \n",
    "        how = 'left', \n",
    "        on = ['country', 'harvest_group','crop_year', 'crop_year_beg', 'crop_year_end'])\n",
    "        \n",
    "producer_cropyear = \\\n",
    "    producer_cropyear \\\n",
    "        .merge(dfs['exports_crop_year'], \n",
    "        how = 'left', \n",
    "        on = ['country', 'harvest_group','crop_year', 'crop_year_beg', 'crop_year_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculated closing stock equals opening stock plus production, less consumption and exports\n",
    "def close_stock_calc(df, scale):\n",
    "    return(\n",
    "        np.fmax(0, \n",
    "            np.round(\n",
    "                df[f'openstock_{scale}'] \n",
    "                + df[f'production_{scale}']\n",
    "                - df[f'consumption_{scale}']\n",
    "                - df[f'exports_{scale}']\n",
    "            , 2)\n",
    "        )\n",
    "    )\n",
    "\n",
    "## closing stock based on time-shifted opening stocks\n",
    "def close_stock_shift(df, scale):\n",
    "    open_shift = \\\n",
    "    df \\\n",
    "        .groupby('country')\\\n",
    "            [f'openstock_{scale}'] \\\n",
    "                .shift(-1)\n",
    "    return(open_shift)\n",
    "\n",
    "## stock adjustment -- difference between calculated and shifted closing stocks\n",
    "def stock_adj(df, scale):\n",
    "    return(close_stock_shift(df,scale) - close_stock_calc(df, scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer_cropyear['closestock_1k_bags'] = close_stock_calc(producer_cropyear, '1k_bags')\n",
    "producer_cropyear['closestock_kg'] = close_stock_calc(producer_cropyear, 'kg')\n",
    "producer_cropyear['closestock_lb'] = close_stock_calc(producer_cropyear, 'lb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer_cropyear.sort_values(['country', 'crop_year_beg'], inplace=True)\n",
    "producer_cropyear['stock_adj_1k_bags'] = stock_adj(producer_cropyear, '1k_bags')\n",
    "producer_cropyear['stock_adj_kg'] = stock_adj(producer_cropyear, 'kg')\n",
    "producer_cropyear['stock_adj_lb'] = stock_adj(producer_cropyear, 'lb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrymap = pd.DataFrame(\n",
    "    {\n",
    "    'country' : ['Democratic Republic of Congo', 'Tanzania', 'Trinidad & Tobago', 'Venezuela'],\n",
    "    'country_pop' : ['Democratic Republic of the Congo', 'United Republic of Tanzania', 'Trinidad and Tobago', 'Venezuela (Bolivarian Republic of)']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer_cropyear = \\\n",
    "    producer_cropyear \\\n",
    "        .merge(countrymap, how = 'left', on='country', suffixes = ['', '_pop']) \\\n",
    "            .assign(country_pop = lambda x: np.where(x.country_pop.isna(), x.country, x.country_pop))\n",
    "\n",
    "producer_cropyear = \\\n",
    "    producer_cropyear \\\n",
    "        .merge(population, how = 'left', left_on=['country_pop', 'crop_year_beg'], right_on = ['country', 'year'], suffixes = ['', '_y']) \\\n",
    "            .drop(columns=['country_y', 'year']) \\\n",
    "                .rename(columns={'population_boy' : 'population_beg'})\n",
    "\n",
    "producer_cropyear = \\\n",
    "    producer_cropyear \\\n",
    "        .merge(population, how = 'left', left_on=['country_pop', 'crop_year_end'], right_on = ['country', 'year'], suffixes = ['', '_y']) \\\n",
    "            .drop(columns=['country_y', 'year', 'population_mid_y']) \\\n",
    "                .rename(columns={'population_boy' : 'population_end'})\n",
    "\n",
    "producer_cropyear.drop(columns='country_pop', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "exports_calendar_year = \\\n",
    "dfs['exports_calendar_year'] \\\n",
    "    .merge(countrymap, how = 'left', on='country', suffixes = ['', '_pop']) \\\n",
    "    .assign(country_pop = lambda x: np.where(x.country_pop.isna(), x.country, x.country_pop)) \n",
    "\n",
    "exports_calendar_year = \\\n",
    "    exports_calendar_year \\\n",
    "        .merge(population, how = 'left', left_on=['country_pop', 'calendar_year'], right_on = ['country', 'year'], suffixes = ['', '_y']) \\\n",
    "            .drop(columns=['country_y', 'year'])\n",
    "            \n",
    "exports_calendar_year.drop(columns='country_pop', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_indicators = \\\n",
    "dfs['indicator_prices'] \\\n",
    "    .loc[\n",
    "        lambda x: x.calendar_month == 'January', \n",
    "        [\n",
    "            'calendar_year',\n",
    "            'indicator_name',\n",
    "            'indicator_price_cents_per_lb_ann',\n",
    "            'indicator_price_dollars_per_lb_ann'\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "annual_indicators['calendar_year'] = annual_indicators['calendar_year'].astype('int64')\n",
    "\n",
    "grower_vs_indicator = dfs['prices_paid_to_growers']\n",
    "grower_vs_indicator['calendar_year'] = grower_vs_indicator['calendar_year'].astype('int64')\n",
    "\n",
    "grower_vs_indicator = \\\n",
    "    grower_vs_indicator \\\n",
    "    .merge(\n",
    "        annual_indicators,\n",
    "        how='left',\n",
    "        on=['indicator_name', 'calendar_year']\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('coffee_market_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef026c5abf575ce9a074a52cc5f8f2ec2923cc7632f8508212c71efb4a1eb1e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
